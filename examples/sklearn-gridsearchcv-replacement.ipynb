{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn hyperparameter search wrapper\n",
    "\n",
    "Iaroslav Shcherbatyi, Tim Head and Gilles Louppe. June 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example assumes basic familiarity with [scikit-learn](http://scikit-learn.org/stable/index.html). \n",
    "\n",
    "Search for parameters of machine learning models that result in best cross-validation performance is necessary in almost all practical cases to get a model with best generalization estimate. A standard approach in scikit-learn is using `GridSearchCV` class, which takes a set of values for every parameter to try, and simply enumerates all combinations of parameter values. The complexity of such search grows exponentially with addition of new parameters. A more scalable approach is using `RandomizedSearchCV`, which however does not take advantage of the structure of a search space.\n",
    "\n",
    "Scikit-optimize provides a drop in replacement for `GridSearchCV`, which utilizes Bayesian Optimization where a predictive model reffered to as \"surrogate\" is used to model the search space and utilized in order to arrive at good parameter values combination as soon as possible.\n",
    "\n",
    "Note: for a manual hyperparameter optimization example, see \"Hyperparameter Optimization\" notebook.\n",
    "\n",
    "## Minimal example\n",
    " \n",
    "A minimal example of optimizing hyperparameters of SVC (Support Vector machine Classifier) is given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.985894580549\n",
      "test score: 0.982222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_digits(10, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt = BayesSearchCV(\n",
    "    SVC(),\n",
    "    {\n",
    "        'C': (1e-6, 1e+6, 'log-uniform'),  \n",
    "        'gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'degree': (1, 8),  # integer valued parameter\n",
    "        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=32\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced example \n",
    "\n",
    "In practice, one wants to enumerate over multiple predictive model classes, with different search spaces and number of evaluations per class. An example of such search over parameters of Linear SVM, Kernel SVM and decision trees is given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.991833704529\n",
      "test score: 0.993333333333\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_digits(10, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n",
    "\n",
    "# used to try different model classes\n",
    "pipe = Pipeline([\n",
    "    ('model', SVC())\n",
    "])\n",
    "\n",
    "# single categorical value of 'model' parameter is used  to set the model class\n",
    "lin_search = {\n",
    "    'model': Categorical([LinearSVC()]),\n",
    "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "dtc_search = {\n",
    "    'model': Categorical([DecisionTreeClassifier()]),\n",
    "    'model__max_depth': Integer(1,32),\n",
    "    'model__min_samples_split': Real(1e-3, 1.0, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "svc_search = {\n",
    "    'model': Categorical([SVC()]),\n",
    "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
    "    'model__degree': Integer(1,8),\n",
    "    'model__kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    [(lin_search, 16), (dtc_search, 24), (svc_search, 32)], # (parameter space, # of evaluations)\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
